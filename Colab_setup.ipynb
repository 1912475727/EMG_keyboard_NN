{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Setup for Local Training\n",
        "\n",
        "This notebook is configured for local training with NVIDIA GPU.\n",
        "\n",
        "**Prerequisites:**\n",
        "- NVIDIA GPU with CUDA support\n",
        "- Python 3.11+ installed\n",
        "- Virtual environment activated (if using venv)\n",
        "- Dataset downloaded to `data/` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.3.0+cu121\n",
            "CUDA available: True\n",
            "CUDA version: 12.1\n",
            "GPU device: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n",
            "GPU memory: 12.82 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:209: UserWarning: \n",
            "NVIDIA GeForce RTX 5070 Ti Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
            "If you want to use the NVIDIA GeForce RTX 5070 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ WARNING: CUDA not available. Training will be slow on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Navigate to Project Directory\n",
        "\n",
        "Make sure you're in the project root directory. If running from a different location, adjust the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\n",
            "✓ Found emg2qwerty package\n",
            "✓ Found data directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get current working directory\n",
        "project_root = Path.cwd()\n",
        "print(f\"Current directory: {project_root}\")\n",
        "\n",
        "# Verify we're in the right place (should have emg2qwerty folder)\n",
        "if (project_root / \"emg2qwerty\").exists():\n",
        "    print(\"✓ Found emg2qwerty package\")\n",
        "else:\n",
        "    print(\"⚠️ Warning: emg2qwerty package not found. Make sure you're in the project root.\")\n",
        "\n",
        "# Verify dataset directory exists\n",
        "if (project_root / \"data\").exists():\n",
        "    print(\"✓ Found data directory\")\n",
        "else:\n",
        "    print(\"⚠️ Warning: data directory not found. Dataset should be in 'data/' folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install/Verify Required Packages\n",
        "\n",
        "**Note:** If using a virtual environment, make sure it's activated before running this cell.\n",
        "\n",
        "If packages are already installed, this will just verify/upgrade them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 621, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 478, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 372, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 834, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 464, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3123, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3178, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3641, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3701, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Temp\\ipykernel_74076\\714480966.py\", line 10, in <module>\n",
            "    import pytorch_lightning as pl\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\__init__.py\", line 35, in <module>\n",
            "    from pytorch_lightning.callbacks import Callback  # noqa: E402\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\__init__.py\", line 14, in <module>\n",
            "    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\batch_size_finder.py\", line 24, in <module>\n",
            "    from pytorch_lightning.callbacks.callback import Callback\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\callback.py\", line 25, in <module>\n",
            "    from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\types.py\", line 27, in <module>\n",
            "    from torchmetrics import Metric\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\__init__.py\", line 14, in <module>\n",
            "    from torchmetrics import functional  # noqa: E402\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\functional\\__init__.py\", line 14, in <module>\n",
            "    from torchmetrics.functional.audio.pit import permutation_invariant_training, pit_permutate\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\functional\\audio\\__init__.py\", line 14, in <module>\n",
            "    from torchmetrics.functional.audio.pit import permutation_invariant_training, pit_permutate  # noqa: F401\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\functional\\audio\\pit.py\", line 22, in <module>\n",
            "    from torchmetrics.utilities.imports import _SCIPY_AVAILABLE\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\__init__.py\", line 1, in <module>\n",
            "    from torchmetrics.utilities.checks import check_forward_full_state_property  # noqa: F401\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\checks.py\", line 25, in <module>\n",
            "    from torchmetrics.utilities.data import select_topk, to_onehot\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\data.py\", line 19, in <module>\n",
            "    from torchmetrics.utilities.imports import _TORCH_GREATER_EQUAL_1_12, _XLA_AVAILABLE\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\imports.py\", line 112, in <module>\n",
            "    _TORCHVISION_GREATER_EQUAL_0_8: Optional[bool] = _compare_version(\"torchvision\", operator.ge, \"0.8.0\")\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\imports.py\", line 78, in _compare_version\n",
            "    if not _module_available(package):\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\imports.py\", line 59, in _module_available\n",
            "    module = import_module(module_names[0])\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
            "    torch.manual_seed = disable(torch.manual_seed)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
            "    return DisableContext()(fn)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
            "    (filename is None or trace_rules.check(fn))\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
            "    return check_verbose(obj, is_inlined_call).skipped\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
            "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
            "    rule = get_torch_obj_rule_map().get(obj, None)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
            "    obj = load_object(k)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
            "    val = _load_obj_from_str(x[0])\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
            "    return getattr(importlib.import_module(module), obj_name)\n",
            "  File \"C:\\Users\\junji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
            "    values=torch.randn(3, 3, device=\"meta\"),\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  values=torch.randn(3, 3, device=\"meta\"),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Key packages imported successfully\n",
            "  - PyTorch Lightning: 1.8.6\n",
            "  - PyTorch: 2.3.0+cu121\n",
            "  - Hydra: 1.3.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# Uncomment the line below if you need to install/update packages\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# Or if using conda:\n",
        "# !conda env update -f environment.yml\n",
        "\n",
        "# Verify key packages\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "    import torch\n",
        "    import hydra\n",
        "    print(\"✓ Key packages imported successfully\")\n",
        "    print(f\"  - PyTorch Lightning: {pl.__version__}\")\n",
        "    print(f\"  - PyTorch: {torch.__version__}\")\n",
        "    print(f\"  - Hydra: {hydra.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Missing package: {e}\")\n",
        "    print(\"Run: pip install -r requirements.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start Your Experiments!\n",
        "\n",
        "**Important:**\n",
        "- Make sure the dataset is in the `data/` directory\n",
        "- Logs will be saved to `logs/YYYY-MM-DD/HH-MM-SS/`\n",
        "- Checkpoints are saved to `logs/.../checkpoints/`\n",
        "- TensorBoard logs are in `logs/.../logs/tensorboard/`\n",
        "\n",
        "**Monitor Training:**\n",
        "- View real-time progress in TensorBoard: `tensorboard --logdir logs/`\n",
        "- Or check the console output below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "**Configuration:**\n",
        "- GPU: Automatically detected (configured in `config/base.yaml`)\n",
        "- Checkpoints: Saved to `logs/YYYY-MM-DD/HH-MM-SS/checkpoints/`\n",
        "- Best model: Automatically saved based on `val/CER`\n",
        "- Logs: TensorBoard logs in `logs/.../logs/tensorboard/`\n",
        "\n",
        "**Training Options:**\n",
        "- Single-user baseline: Use command below\n",
        "- Custom epochs: Add `trainer.max_epochs=50` (default is 150)\n",
        "- Custom batch size: Add `batch_size=16` (default is 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-22 16:04:36,688][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 16\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 50\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "  logger:\n",
            "  - _target_: pytorch_lightning.loggers.TensorBoardLogger\n",
            "    save_dir: ${hydra:runtime.output_dir}/logs\n",
            "    name: tensorboard\n",
            "    version: null\n",
            "    log_graph: true\n",
            "    default_hp_metric: true\n",
            "  log_every_n_steps: 10\n",
            "  val_check_interval: 0.5\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "  logging_interval: step\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "- _target_: pytorch_lightning.callbacks.TQDMProgressBar\n",
            "  refresh_rate: 10\n",
            "\n",
            "[2026-02-22 16:04:36,691][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2026-02-22 16:04:36,810][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "\n",
            "Sanity Checking: 0it [00:00, ?it/s]\n",
            "                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 1501\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:209: UserWarning: \n",
            "NVIDIA GeForce RTX 5070 Ti Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
            "If you want to use the NVIDIA GeForce RTX 5070 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(\n",
            "Missing logger folder: c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\logs\\2026-02-22\\16-04-36/logs\\tensorboard\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pl_bolts\\__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pl_bolts\\models\\self_supervised\\amdim\\amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pl_bolts\\losses\\self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\hydra\\_internal\\instantiate\\_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:261: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
            "  rank_zero_warn(\n",
            "Error executing job with overrides: ['user=single_user', 'trainer.max_epochs=50', 'batch_size=16']\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 645, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1177, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1190, in _run_train\n",
            "    self._run_sanity_check()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1255, in _run_sanity_check\n",
            "    val_loop._reload_evaluation_dataloaders()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py\", line 234, in _reload_evaluation_dataloaders\n",
            "    self.trainer.reset_val_dataloader()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1635, in reset_val_dataloader\n",
            "    self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py\", line 391, in _reset_eval_dataloader\n",
            "    len(dataloader) if has_len_all_ranks(dataloader, self.trainer.strategy, module) else float(\"inf\")\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py\", line 110, in has_len_all_ranks\n",
            "    if total_length == 0:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: CUDA error: no kernel image is available for execution on the device\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\emg2qwerty\\train.py\", line 113, in main\n",
            "    trainer.fit(module, datamodule, ckpt_path=resume_from_checkpoint)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 603, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 63, in _call_and_handle_interrupt\n",
            "    trainer._teardown()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1161, in _teardown\n",
            "    self.strategy.teardown()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\", line 496, in teardown\n",
            "    self.lightning_module.cpu()\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\lightning_lite\\utilities\\device_dtype_mixin.py\", line 78, in cpu\n",
            "    return super().cpu()\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 964, in cpu\n",
            "    return self._apply(lambda t: t.cpu())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\torchmetrics\\metric.py\", line 659, in _apply\n",
            "    self._device = fn(torch.zeros(1, device=self.device)).device\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: CUDA error: no kernel image is available for execution on the device\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ]
        }
      ],
      "source": [
        "!python -m emg2qwerty.train \\\n",
        "user=\"single_user\" \\\n",
        "trainer.max_epochs=50 \\\n",
        "batch_size=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing/Evaluation:\n",
        "\n",
        "**Testing Options:**\n",
        "- Test on best checkpoint: Use the checkpoint path from training logs\n",
        "- Test on specific checkpoint: Provide full path to `.ckpt` file\n",
        "- Test with different decoders: `decoder=ctc_greedy` or `decoder=ctc_beam`\n",
        "\n",
        "**Checkpoint Path Format:**\n",
        "- Best model: `logs/YYYY-MM-DD/HH-MM-SS/checkpoints/epoch=X-val_CER=Y.Y.ckpt`\n",
        "- Last model: `logs/YYYY-MM-DD/HH-MM-SS/checkpoints/last.ckpt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoints found. Train a model first.\n"
          ]
        }
      ],
      "source": [
        "# Testing/Evaluation on trained model\n",
        "# Replace the checkpoint path with your actual checkpoint path\n",
        "\n",
        "# Example: Test on best checkpoint (greedy decoding)\n",
        "# !python -m emg2qwerty.train \\\n",
        "#   user=\"single_user\" \\\n",
        "#   checkpoint=\"logs/2024-01-15/14-30-45/checkpoints/epoch=3-val_CER=43.8.ckpt\" \\\n",
        "#   train=False \\\n",
        "#   decoder=ctc_greedy\n",
        "\n",
        "# Example: Test on last checkpoint (beam search decoding)\n",
        "# !python -m emg2qwerty.train \\\n",
        "#   user=\"single_user\" \\\n",
        "#   checkpoint=\"logs/2024-01-15/14-30-45/checkpoints/last.ckpt\" \\\n",
        "#   train=False \\\n",
        "#   decoder=ctc_beam\n",
        "\n",
        "# Example: Find and test on latest checkpoint automatically\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Find latest checkpoint\n",
        "checkpoint_dir = Path(\"logs\")\n",
        "checkpoints = list(checkpoint_dir.glob(\"**/checkpoints/*.ckpt\"))\n",
        "if checkpoints:\n",
        "    latest_ckpt = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
        "    print(f\"Latest checkpoint found: {latest_ckpt}\")\n",
        "    print(f\"\\nTo test, uncomment and run:\")\n",
        "    print(f\"!python -m emg2qwerty.train \\\\\")\n",
        "    print(f'  user=\"single_user\" \\\\')\n",
        "    print(f'  checkpoint=\"{latest_ckpt}\" \\\\')\n",
        "    print(f'  train=False \\\\')\n",
        "    print(f'  decoder=ctc_greedy')\n",
        "else:\n",
        "    print(\"No checkpoints found. Train a model first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Monitor Training with TensorBoard\n",
        "\n",
        "Start TensorBoard in a separate terminal to monitor training in real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No logs directory found yet. Start training first.\n"
          ]
        }
      ],
      "source": [
        "# Start TensorBoard to monitor training\n",
        "# Run this in a separate terminal (not in notebook):\n",
        "# tensorboard --logdir logs/\n",
        "\n",
        "# Or if you want to run it in the background from notebook:\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "log_dir = Path(\"logs\")\n",
        "if log_dir.exists():\n",
        "    print(\"To view TensorBoard, run in a separate terminal:\")\n",
        "    print(f\"  tensorboard --logdir {log_dir.absolute()}\")\n",
        "    print(\"\\nThen open: http://localhost:6006\")\n",
        "    print(\"\\nOr uncomment below to start TensorBoard in background:\")\n",
        "    # Uncomment to start TensorBoard (will run in background)\n",
        "    # subprocess.Popen([\"tensorboard\", \"--logdir\", str(log_dir.absolute())], \n",
        "    #                  stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    # print(\"TensorBoard started! Open http://localhost:6006\")\n",
        "else:\n",
        "    print(\"No logs directory found yet. Start training first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
