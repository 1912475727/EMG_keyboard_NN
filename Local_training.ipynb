{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Local training — emg2qwerty\n",
        "\n",
        "Run training on your local machine (Windows) with the project venv and GPU.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Python 3.11+ with venv at `venv/`\n",
        "- Dataset in `data/` (same layout as in the repo)\n",
        "- For **RTX 5070 Ti** (sm_120): PyTorch nightly with CUDA 12.8 (see Step 1)\n",
        "\n",
        "**Kernel:** Select the interpreter from `venv` (e.g. `./venv/Scripts/python.exe`) so `!python` uses it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check GPU and PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.12.0.dev20260225+cu128\n",
            "CUDA available: True\n",
            "CUDA version: 12.8\n",
            "Device: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n",
            "GPU memory: 12.82 GB\n",
            "GPU tensor test: OK\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    # Quick GPU op test\n",
        "    x = torch.randn(2, 2).cuda()\n",
        "    print(\"GPU tensor test: OK\")\n",
        "else:\n",
        "    print(\"No CUDA. Training will use CPU (slower).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**RTX 5070 Ti (sm_120):** If you see \"no kernel image is available\" or \"sm_120 is not compatible\", install PyTorch nightly with CUDA 12.8:\n",
        "\n",
        "```bash\n",
        "pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Verify project and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\n",
            "✓ emg2qwerty package found\n",
            "✓ data/ found (0 .h5 files)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "project_root = Path.cwd()\n",
        "print(f\"Project root: {project_root}\")\n",
        "\n",
        "assert (project_root / \"emg2qwerty\").is_dir(), \"Run this notebook from the project root (where emg2qwerty/ lives).\"\n",
        "print(\"✓ emg2qwerty package found\")\n",
        "\n",
        "data_dir = project_root / \"data\"\n",
        "if data_dir.is_dir():\n",
        "    n_files = len(list(data_dir.rglob(\"*.h5\")))\n",
        "    print(f\"✓ data/ found ({n_files} .h5 files)\")\n",
        "else:\n",
        "    print(\"⚠ data/ not found. Put the dataset in data/ (see config user/single_user for layout).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Single run with defaults from `config/base.yaml` and `config/model/cnn_transformer_ctc.yaml`:\n",
        "- Model: CNN + Transformer encoder (CTC)\n",
        "- Data: `dataset.root` = current working directory + `/data`\n",
        "- Logs and checkpoints: `logs/YYYY-MM-DD/HH-MM-SS/`\n",
        "\n",
        "**Windows / local:** Use **`cluster=basic`** so training runs in-process (no submitit). The default `cluster=local` uses submitit and can fail on Windows (e.g. FileNotFoundError, SIGKILL). All commands below include `cluster=basic`.\n",
        "\n",
        "**Progress bar:** When you run from this notebook, progress may not update live (buffering). Use the **\"Run training (live output)\"** cell below to see progress in the notebook, or run the same command in a **terminal** (PowerShell, venv activated) for the usual live progress bar.\n",
        "\n",
        "**Overrides you can add:**\n",
        "- `trainer.max_epochs=50` — fewer epochs\n",
        "- `batch_size=16` — smaller batch\n",
        "- `trainer.accelerator=cpu` — force CPU\n",
        "- `num_workers=4` — faster data loading (only if you have enough RAM/paging file; default 0 avoids Windows \"paging file too small\" with worker processes)\n",
        "- `model=tds_conv_ctc` — TDS baseline (plain CTC)\n",
        "- `model=tds_conv_crctc` — TDS baseline + AdamW + CR-CTC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TDS + AdamW + CR-CTC (baseline with CR-CTC loss):**  \n",
        "Single run with TDS model, AdamW optimizer, and CR-CTC (entropy regularization):\n",
        "\n",
        "```\n",
        "python -u -m emg2qwerty.train model=tds_conv_crctc cluster=basic trainer.accelerator=gpu trainer.devices=1\n",
        "```\n",
        "\n",
        "Logs and checkpoints go to `logs/YYYY-MM-DD/HH-MM-SS/`. Tune CR-CTC in `config/model/tds_conv_crctc.yaml` (e.g. `module.cr_ctc_entropy_weight`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Single-user training (GPU, default config)\n",
        "# Use -u for unbuffered output so logs flush; progress bar may still not update live in notebook.\n",
        "!python -m emg2qwerty.train user=single_user cluster=basic trainer.accelerator=gpu trainer.devices=1 --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test (evaluate checkpoint)\n",
        "\n",
        "After training, run evaluation on the test set using a saved checkpoint. This mirrors the **Testing** section in `Colab_setup.ipynb` used for cloud training (same `train=False` + `decoder=ctc_greedy` flow)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Checkpoint path:** Set `checkpoint_path` in the cell below (path often contains `=` and `,`, e.g. `job0_trainer.devices=1,user=single_user`, `epoch=109-step=13140.ckpt`). The cell uses a variable + subprocess so Hydra receives the path as one quoted value and does not hit \"mismatched input '='\".\n",
        "- **Model must match checkpoint:** Default config uses **CNN Transformer** (`cnn_transformer_ctc`). If your checkpoint is from a **TDS** model (e.g. `models/personalized-finetuned/user7.ckpt`), set **`model_override = \"tds_conv_crctc\"`** in the cell below so the architecture matches (otherwise you get \"Missing key(s) / Unexpected key(s)\" in state_dict).\n",
        "- **Decoder:** `decoder=ctc_greedy` runs greedy CTC decoding and computes test CER.\n",
        "- **Local:** Use `cluster=basic`. For cloud runs, see `Colab_setup.ipynb`.\n",
        "- **Where to see testing results:** Open **`latest_test_results.txt`** in the **project root**. Val and test metrics are written there; if the run errors, the file contains the traceback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-27 15:42:34,024][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "noise:\n",
            "  _target_: emg2qwerty.transforms.AdditiveGaussianNoise\n",
            "  scale: 0.04\n",
            "channel_dropout:\n",
            "  _target_: emg2qwerty.transforms.ChannelDropout\n",
            "  prob: 0.1\n",
            "  channel_dim: -1\n",
            "gain_scaling:\n",
            "  _target_: emg2qwerty.transforms.ChannelGainScaling\n",
            "  max_scale: 0.2\n",
            "  channel_dim: -1\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.CNNTransformerCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  cnn_layers: 3\n",
            "  cnn_kernel_size: 31\n",
            "  transformer_layers: 4\n",
            "  n_heads: 8\n",
            "  ff_dim: null\n",
            "  dropout: 0.1\n",
            "  max_len: 5000\n",
            "  use_cr_ctc: true\n",
            "  cr_ctc_consistency_weight: 0.0\n",
            "  cr_ctc_entropy_weight: 0.01\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.AdamW\n",
            "  lr: 0.001\n",
            "  weight_decay: 0.01\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
            "    mode: ${monitor_mode}\n",
            "    factor: 0.1\n",
            "    patience: 20\n",
            "    min_lr: 1.0e-06\n",
            "  monitor: ${monitor_metric}\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 0\n",
            "train: false\n",
            "checkpoint: C:/Users/junji/Documents/C147_final/emg2qwerty/logs/2026-02-26/14-32-34/job0_trainer.devices=1,user=single_user/checkpoints/epoch=109-step=13140.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "  logger:\n",
            "  - _target_: pytorch_lightning.loggers.TensorBoardLogger\n",
            "    save_dir: ${hydra:runtime.output_dir}/logs\n",
            "    name: tensorboard\n",
            "    version: null\n",
            "    log_graph: true\n",
            "    default_hp_metric: true\n",
            "  - _target_: pytorch_lightning.loggers.CSVLogger\n",
            "    save_dir: ${hydra:runtime.output_dir}/logs\n",
            "    name: csv\n",
            "    version: null\n",
            "  log_every_n_steps: 10\n",
            "  val_check_interval: 0.5\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "  logging_interval: step\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "- _target_: pytorch_lightning.callbacks.TQDMProgressBar\n",
            "  refresh_rate: 10\n",
            "\n",
            "[2026-02-27 15:42:34,027][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.CNNTransformerCTCModule', 'in_features': 528, 'mlp_features': [384], 'cnn_layers': 3, 'cnn_kernel_size': 31, 'transformer_layers': 4, 'n_heads': 8, 'ff_dim': None, 'dropout': 0.1, 'max_len': 5000, 'use_cr_ctc': True, 'cr_ctc_consistency_weight': 0.0, 'cr_ctc_entropy_weight': 0.01}\n",
            "[2026-02-27 15:42:34,313][__main__][INFO] - Loading module from checkpoint C:/Users/junji/Documents/C147_final/emg2qwerty/logs/2026-02-26/14-32-34/job0_trainer.devices=1,user=single_user/checkpoints/epoch=109-step=13140.ckpt\n",
            "[2026-02-27 15:42:35,006][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "\n",
            "Validation: 0it [00:00, ?it/s]\n",
            "Validation:   0%|          | 0/7 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 7/7 [00:03<00:00,  2.16it/s]\n",
            "Validation DataLoader 0: 100%|██████████| 7/7 [00:03<00:00,  2.15it/s]\n",
            "┌───────────────────────────┬───────────────────────────┐\n",
            "│  Runningstage.validating  │                           │\n",
            "│          metric           │       DataLoader 0        │\n",
            "├───────────────────────────┼───────────────────────────┤\n",
            "│          val/CER          │    14.731945037841797     │\n",
            "│          val/DER          │    1.6836508512496948     │\n",
            "│          val/IER          │     3.677448034286499     │\n",
            "│          val/SER          │     9.370845794677734     │\n",
            "│         val/loss          │    0.7316213846206665     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "\n",
            "Testing: 0it [00:00, ?it/s]\n",
            "Testing:   0%|          | 0/9 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0:   0%|          | 0/9 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0: 100%|██████████| 9/9 [00:04<00:00,  2.20it/s]\n",
            "Testing DataLoader 0: 100%|██████████| 9/9 [00:04<00:00,  2.19it/s]\n",
            "┌───────────────────────────┬───────────────────────────┐\n",
            "│   Runningstage.testing    │                           │\n",
            "│          metric           │       DataLoader 0        │\n",
            "├───────────────────────────┼───────────────────────────┤\n",
            "│         test/CER          │     16.84712028503418     │\n",
            "│         test/DER          │    1.9705500602722168     │\n",
            "│         test/IER          │     4.37418794631958      │\n",
            "│         test/SER          │    10.502382278442383     │\n",
            "│         test/loss         │    0.8271687626838684     │\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "[2026-02-27 15:42:43,291][__main__][INFO] - Validation and test results:\n",
            "{'val_metrics': [{'val/loss': 0.7316213846206665,\n",
            "                  'val/CER': 14.731945037841797,\n",
            "                  'val/IER': 3.677448034286499,\n",
            "                  'val/DER': 1.6836508512496948,\n",
            "                  'val/SER': 9.370845794677734}],\n",
            " 'test_metrics': [{'test/loss': 0.8271687626838684,\n",
            "                   'test/CER': 16.84712028503418,\n",
            "                   'test/IER': 4.37418794631958,\n",
            "                   'test/DER': 1.9705500602722168,\n",
            "                   'test/SER': 10.502382278442383}],\n",
            " 'best_checkpoint': 'C:/Users/junji/Documents/C147_final/emg2qwerty/logs/2026-02-26/14-32-34/job0_trainer.devices=1,user=single_user/checkpoints/epoch=109-step=13140.ckpt'}\n",
            "{'val_metrics': [{'val/loss': 0.7316213846206665,\n",
            "                  'val/CER': 14.731945037841797,\n",
            "                  'val/IER': 3.677448034286499,\n",
            "                  'val/DER': 1.6836508512496948,\n",
            "                  'val/SER': 9.370845794677734}],\n",
            " 'test_metrics': [{'test/loss': 0.8271687626838684,\n",
            "                   'test/CER': 16.84712028503418,\n",
            "                   'test/IER': 4.37418794631958,\n",
            "                   'test/DER': 1.9705500602722168,\n",
            "                   'test/SER': 10.502382278442383}],\n",
            " 'best_checkpoint': 'C:/Users/junji/Documents/C147_final/emg2qwerty/logs/2026-02-26/14-32-34/job0_trainer.devices=1,user=single_user/checkpoints/epoch=109-step=13140.ckpt'}\n",
            "[2026-02-27 15:42:43,292][__main__][INFO] - Results written to C:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\latest_test_results.txt\n",
            "\n",
            "Results (if run completed) are in latest_test_results.txt in project root.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 1501\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\logs\\2026-02-27\\15-42-33/logs\\tensorboard\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:261: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
            "  rank_zero_warn(\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "c:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Single-user testing (evaluate checkpoint on test set)\n",
        "# Paths with \"=\" or \",\" (e.g. job0_trainer.devices=1,user=single_user) must be passed quoted.\n",
        "# Using a variable + subprocess avoids Hydra \"mismatched input '='\" errors.\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "checkpoint_path = Path(r\"C:\\Users\\junji\\Documents\\C147_final\\emg2qwerty\\logs\\2026-02-26\\14-32-34\\job0_trainer.devices=1,user=single_user\\checkpoints\\epoch=109-step=13140.ckpt\")\n",
        "# Model must match checkpoint: None = CNN Transformer (e.g. logs/.../epoch=109-step=13140.ckpt); \"tds_conv_crctc\" = TDS (e.g. user7.ckpt)\n",
        "model_override = None\n",
        "if not checkpoint_path.is_absolute():\n",
        "    checkpoint_path = Path.cwd() / checkpoint_path\n",
        "\n",
        "override_checkpoint = f'checkpoint=\"{checkpoint_path.as_posix()}\"'\n",
        "cmd = [\n",
        "    sys.executable, \"-m\", \"emg2qwerty.train\",\n",
        "    \"user=single_user\", \"cluster=basic\", override_checkpoint,\n",
        "    \"train=false\", \"trainer.accelerator=gpu\", \"trainer.devices=1\", \"decoder=ctc_greedy\",\n",
        "]\n",
        "if model_override:\n",
        "    cmd.insert(-1, f\"model={model_override}\")\n",
        "proc = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace', cwd=Path.cwd())\n",
        "if proc.stdout:\n",
        "    print(proc.stdout)\n",
        "if proc.stderr:\n",
        "    print(proc.stderr, file=sys.stderr)\n",
        "print('Results (if run completed) are in latest_test_results.txt in project root.')\n",
        "proc.check_returncode()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: short sanity run (1 epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run to test the pipeline with 1 epoch only:\n",
        "# !python -u -m emg2qwerty.train user=single_user cluster=basic trainer.accelerator=gpu trainer.devices=1 trainer.max_epochs=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: TensorBoard (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TensorBoard** (from project root):\n",
        "\n",
        "```bash\n",
        "tensorboard --logdir logs/\n",
        "```\n",
        "\n",
        "Then open http://localhost:6006 to monitor loss and metrics.\n",
        "\n",
        "**CSV metrics (CER, loss, etc.):** Each run writes `logs/YYYY-MM-DD/HH-MM-SS/.../logs/csv/version_0/metrics.csv` with columns for `train_loss_epoch`, `val/loss`, `val/CER`, and other logged metrics per epoch. In multirun, each job has its own directory and thus its own `metrics.csv` for easy comparison."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
